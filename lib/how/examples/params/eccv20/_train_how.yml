# Common parameters for training

experiment: null # Name of the experiment folder, if null, the yaml file name will be used

demo_train:
  data_folder: how_data # Data path relative to the package root (can be absolute path)
  exp_folder: how_data/experiments # Experiment path relative to the package root (can be absolute path)
  gpu_id: 0 # Gpu id to perform training on (asmk can have a different gpu id)

training:
  epochs: 20 # Number of epochs to train for
  optimizer:
    lr: null # Adam learning rate
    weight_decay: 1.e-4 # Adam weight decay
  loss:
    margin: 0.8 # Contrastive loss margin
  lr_scheduler:
    gamma: 0.99 # Gamma parameter in learning rate decay

  initialize_dim_reduction:
    images: 5000 # Number of training images (first in the dataset) to use for initializing the dimensionality reduction layer with PCA whitening
    features_num: null # Number of features to extract per image (null for the default value of model.runtime.features_num)

  dataset:
    name: retrieval-SfM-120k # Training dataset name
    mode: train # Training dataset split
    imsize: 1024 # Image size to train on
    nnum: 5 # Number of negatives in hard negative mining
    qsize: 2000 # Number of query images (epoch size)
    poolsize: 20000 # Pool size to choose hard negatives from
  loader:
    batch_size: 5 # Number of queries in a batch

validation:
  # Picking the best epoch is based on the first score that exists:
  # - mAP of local descriptor on val_eccv20 dataset (if 'val_eccv20' in local_descriptor.datasets)
  # - mAP of global descriptor on val_eccv20 dataset (if 'val_eccv20' in global_descriptor.datasets)
  # - epoch number (always defined)
  global_descriptor:
    frequency: null # How often (number of epochs) to run global descriptor validation
    datasets: [] # On which datasets to run global descriptor validation
  local_descriptor:
    frequency: 5 # How often (number of epochs) to run local descriptor validation
    datasets: [val_eccv20] # On which datasets to run local descriptor validation
    codebook_training:
      images: 20000 # Number of training images (first in the dataset) to use for learning the codebook
      scales: [1] # Scales for multiscale inference
    asmk:
      __template__: _asmk_how.yml # load from separate file

model:
  architecture: null # Backbone network
  pretrained: True # Whether to start with a model pre-trained on ImageNet (from torchvision.models)
  skip_layer: null # How many layers of blocks will be skipped, counting from end
  dim_reduction:
    dim: 128 # The output dimension
  smoothing:
    kernel_size: 3 # Kernel size of the pooling

  runtime:
    mean_std: [[0.485, 0.456, 0.406], [0.229, 0.224, 0.225]] # Mean and std normalization of input data
    image_size: 1024
    features_num: 1000 # Number of local features to keep in inference (sorted by attention)
    scales: [2.0, 1.414, 1.0, 0.707, 0.5, 0.353, 0.25] # Scales for multiscale inference
    training_scales: [1] # Scales to aggregate into a global descriptor during training
